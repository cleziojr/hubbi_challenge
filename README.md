# Desafio T√©cnico - Hubbi

Este projeto implementa uma **pipeline automatizada de ETL** que extrai dados de produtos de um site de testes, processa e armazena em um **banco PostgreSQL**.  

A solu√ß√£o √© **100% containerizada**, utilizando **Docker Compose** para orquestrar:  

- A aplica√ß√£o Python (`app`)  
- O navegador para web scraping (`selenium/firefox`)  
- O banco de dados (`PostgreSQL`)  

---

## üõ†Ô∏è Pr√©-requisitos

Para rodar o projeto, voc√™ precisa ter instalado:  

1. **Git** ‚Äì para clonar o reposit√≥rio.  
2. **Docker e Docker Compose v2** ‚Äì essencial para executar toda a pipeline.  
3. **Python 3.8+** (opcional) ‚Äì apenas se desejar consultar o notebook localmente.  

---

### Guia de instala√ß√£o dos pr√©-requisitos

**Windows e macOS:**  

- Instale o Docker Desktop. O Docker Compose v2 j√° vem inclu√≠do.  

**Linux (Ubuntu/Debian):**  

```bash
sudo apt-get update
sudo apt-get install docker.io docker-compose-plugin
````

> ‚ö†Ô∏è Recomendado: siga os passos p√≥s-instala√ß√£o do Docker para usar sem privil√©gios de root.

```bash
docker --version
docker compose version
```

---

## üíª Observa√ß√µes sobre Docker em diferentes sistemas operacionais

### Windows e macOS

* O **Docker Desktop** j√° inclui Docker Engine e Docker Compose v2.
* Comandos s√£o exatamente os mesmos que os listados abaixo.

### Linux (Ubuntu/Debian)

* Pode ser necess√°rio usar `sudo` para os comandos Docker:

```bash
sudo docker compose up -d --build
sudo docker compose logs -f app
sudo docker compose down
```

* Para n√£o precisar usar `sudo` sempre, adicione seu usu√°rio ao grupo docker:

```bash
sudo usermod -aG docker $USER
```

Depois fa√ßa logout/login para aplicar.

### Observa√ß√µes gerais

* Todos os comandos devem ser executados **dentro do diret√≥rio do projeto**, onde est√° o `docker-compose.yml`.
* Use sempre `docker compose` (v2) e n√£o o antigo `docker-compose`.
* Em PowerShell/Windows, caminhos relativos podem usar `.\` em vez de `./`.

---

## üîÑ Restaurando o banco a partir do `.dump`

E caso voc√™ queira restaurar os dados a partir do arquivo `.dump` (por exemplo, para iniciar a pipeline com os dados j√° carregados), siga o passo a passo abaixo. **Importante:** reflita antes de subir o container se voc√™ deseja restaurar ou n√£o, para evitar inconsist√™ncias.

O backup bin√°rio est√° localizado em `./data/hubbi_dw_backup.dump`.

### 1Ô∏è‚É£ Restaurar antes de subir o container (recomendado)

1. Certifique-se de que nenhum container do PostgreSQL est√° rodando:

```bash
docker compose down
```

2. Suba apenas o servi√ßo do banco (opcional, mas √∫til para controle):

```bash
docker compose up -d db
```

3. Acesse o shell do container:

```bash
docker compose exec db bash
```

4. Crie o banco vazio:

```bash
createdb -U hubbi hubbi_dw
```

5. Restaure o dump dentro do container:

```bash
pg_restore -U hubbi -d hubbi_dw /data/hubbi_dw_backup.dump
```

6. Saia do container (`exit`) e ent√£o suba os demais servi√ßos normalmente:

```bash
docker compose up -d --build
docker compose logs -f app
```

---

### 2Ô∏è‚É£ Restaurar com o container j√° em execu√ß√£o

Se voc√™ j√° subiu o container `db` com a aplica√ß√£o:

1. Acesse o container:

```bash
docker compose exec db bash
```

2. Crie um banco novo (ou drope o existente, se quiser sobrescrever):

```bash
dropdb -U hubbi hubbi_dw
createdb -U hubbi hubbi_dw
```

3. Restaure o dump:

```bash
pg_restore -U hubbi -d hubbi_dw /data/hubbi_dw_backup.dump
```

4. Reinicie o container da aplica√ß√£o (`app`) para garantir que ela se conecte ao banco atualizado:

```bash
docker compose restart app
```

---

### üí° Observa√ß√µes importantes

* Restaurar o dump **antes de subir o container** √© mais seguro e evita inconsist√™ncias.
* Se optar por restaurar com o container j√° rodando, lembre-se de dropar/recriar o banco ou usar um banco alternativo.
* O `.dump` √© bin√°rio (`pg_dump -Fc`), garantindo que **tabelas, √≠ndices e dados** sejam restaurados exatamente como estavam.

---

## Executando a pipeline

### 1. Clone o reposit√≥rio

```bash
git clone https://github.com/cleziojr/hubbi_challenge.git
cd hubbi_challenge
```

### 2. Suba os containers

```bash
docker compose up -d --build
```

O comando cria as imagens e inicia os servi√ßos `app`, `db` e `selenium-firefox`. O script `main.py` ser√° executado automaticamente dentro do container `app`.

### 3. Acompanhe os logs de execu√ß√£o

```bash
docker compose logs -f app
```

> Pressione `Ctrl+C` para sair dos logs (isso **n√£o serve para os containers**).

### 4. Consulte a an√°lise explorat√≥ria (EDA)

O projeto inclui um **notebook `eda_hubbi.ipynb`** com an√°lises explorat√≥rias e gr√°ficos sobre os dados coletados.
Ele pode ser **consultado diretamente como arquivo `.ipynb`**, sem necessidade de execu√ß√£o, permitindo revisar gr√°ficos, tabelas e insights obtidos.

### 5. Desligue a pipeline

```bash
docker compose down
docker compose down -v
```

---

## üí° Decis√µes de design e arquitetura

### Estrat√©gia de ETL

* **Carga de dados:** a carga no banco de dados √© efetuada a cada p√°gina de produtos iterada. Esta decis√£o foi um *trade-off* consciente para alcan√ßar um equil√≠brio entre performance e persist√™ncia:

  * √â mais seguro do que efetuar a carga apenas ao final da execu√ß√£o (o que elevaria a performance, mas diminuiria a garantia de persist√™ncia em caso de falha).

  * √â muito mais perform√°tico do que efetuar a carga a cada produto (o que diminuiria drasticamente a performance, mas garantiria ao m√°ximo a persist√™ncia).

* **Integridade dos dados:** antes de inserir os dados de um produto no banco, o algoritmo sempre verifica se aquele produto j√° foi inserido anteriormente. Desta forma, garante-se a integridade e apenas os dados novos sobem para o banco, permitindo que a pipeline seja executada repetidas vezes sem gerar duplicidade.

* **Ferramenta de extra√ß√£o:** optei pelo selenium para a extra√ß√£o dos dados. Embora eu j√° tenha criado pipelines utilizando requests e beautifulsoup para parsear e extrair o conte√∫do, o selenium foi escolhido neste projeto por eu achar mais f√°cil de lidar, o que permitiu um desenvolvimento mais √°gil.

### Infraestrutura

* **Containeriza√ß√£o:** Docker garante ambiente consistente e port√°vel.
* **Orquestra√ß√£o:** `docker-compose` gerencia `app`, `db` e `selenium-firefox`.

### Seguran√ßa e credenciais

* As credenciais do banco de dados (usu√°rio, senha, host) est√£o armazenadas em vari√°veis de ambiente, lidas a partir de um arquivo .env. Esta √© uma pr√°tica de seguran√ßa fundamental para proteger dados sens√≠veis.

* **Disclaimer para avalia√ß√£o:** tenho ci√™ncia de que, em um ambiente de produ√ß√£o, o arquivo .env **nunca** √© "commitado" no reposit√≥rio. Para facilitar a execu√ß√£o e corre√ß√£o deste desafio, o arquivo .env foi excepcionalmente inclu√≠do.

---

## An√°lise explorat√≥ria dos dados (EDA)

* **Foco na ruptura de estoque:** durante a an√°lise, foi observado (conforme detalhado no notebook eda_hubbi.py) uma grande similaridade no comportamento estat√≠stico de diversas vari√°veis (como pre√ßo, peso e dimens√µes).

* Dada a baixa varia√ß√£o estat√≠stica em atributos como pre√ßo e dimens√µes, a an√°lise foi direcionada ao insight de maior relev√¢ncia para a empresa: a falta de estoque (ruptura). Aplicando o princ√≠po de pareto (80/20), pude identificar que o problema est√° altamente concentrado. Isso permite que, ao inv√©s de uma solu√ß√£o gen√©rica, seja poss√≠vel priorizar categorias e marcas espec√≠ficas que trar√£o o maior impacto na redu√ß√£o de perdas por ruptura.

